{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5cbe5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cfc646b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device settings\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bda5fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "def load_model():\n",
    "    CHECKPOINT = \"microsoft/Florence-2-base-ft\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(CHECKPOINT, trust_remote_code=True).to(device, dtype=torch_dtype)\n",
    "    processor = AutoProcessor.from_pretrained(CHECKPOINT, trust_remote_code=True)\n",
    "    return model, processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12984b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanutiwari/miniconda3/envs/Oasis/lib/python3.9/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Florence2LanguageForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    }
   ],
   "source": [
    "model, processor = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28475f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(model,processor, img, task_prompt, phrase=''):\n",
    "\n",
    "    inputs = processor(text=task_prompt+phrase, images=img, return_tensors=\"pt\").to(device, torch_dtype)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            pixel_values=inputs[\"pixel_values\"],\n",
    "            max_new_tokens=512,\n",
    "            num_beams=3,\n",
    "            do_sample=False\n",
    "        )\n",
    "\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "\n",
    "    parsed_answer = processor.post_process_generation(\n",
    "            generated_text,\n",
    "            task=task_prompt,\n",
    "            image_size=(img.width, img.height))\n",
    "\n",
    "    # key = \"<CAPTION_TO_PHRASE_GROUNDING>\"\n",
    "    # key = \"<OPEN_VOCABULARY_DETECTION>\"\n",
    "    key = task_prompt\n",
    "\n",
    "    detections = parsed_answer.get(key, {\"bboxes\": [], \"labels\": []})\n",
    "    bboxes = detections.get(\"bboxes\", [])\n",
    "    labels = detections.get(\"labels\", [])\n",
    "\n",
    "    data = []\n",
    "    area_img  = img.width * img.height\n",
    "\n",
    "    for bbox, label in zip(bboxes, labels):\n",
    "        x_min, y_min, x_max, y_max = map(int, bbox)\n",
    "        bbox_area = (x_max - x_min) * (y_max - y_min)\n",
    "        if bbox_area < 0.7*area_img:\n",
    "            data.append([x_min, y_min, x_max, y_max, label])\n",
    "\n",
    "    return pd.DataFrame(data, columns=[\"x1\", \"y1\", \"x2\", \"y2\", \"object\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4d87571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Object Detection (OD)', '<OD>', '')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = \"Object Detection (OD)\"\n",
    "# task = \"Phrase Grounding (PG)\"\n",
    "# task = \"Image Captioning (IC)\"\n",
    "# task = \"Open Vocabulary Detection (OVD)\"\n",
    "\n",
    "phrase = ''\n",
    "if task == \"Object Detection (OD)\":\n",
    "    task_prompt = \"<OD>\"\n",
    "elif task == \"Phrase Grounding (PG)\":\n",
    "    task_prompt = \"<CAPTION_TO_PHRASE_GROUNDING>\"\n",
    "    phrase = 'tomato'\n",
    "elif task == \"Image Captioning (IC)\":\n",
    "    task_prompt = \"<CAPTION>\"\n",
    "else:\n",
    "    task_prompt = \"<OPEN_VOCABULARY_DETECTION>\"\n",
    "    # phrase = 'Tomato'\n",
    "\n",
    "task , task_prompt , phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f35177d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 520/520 [11:23<00:00,  1.31s/it]\n"
     ]
    }
   ],
   "source": [
    "# Loading dataset images and labels\n",
    "img_folder = 'Images'\n",
    "labels_folder = 'labels'\n",
    "\n",
    "result = []\n",
    "\n",
    "for file in tqdm(np.sort(os.listdir(img_folder))):\n",
    "    if not file.endswith('.JPG'):\n",
    "        continue\n",
    "\n",
    "    # if file == \"0000.JPG\" or file == \"0001.JPG\" or file == \"0002.JPG\":\n",
    "    #     continue\n",
    "\n",
    "    image_path = os.path.join(img_folder, file)\n",
    "    img = Image.open(image_path).convert('RGB')  \n",
    "    # img = img.resize((1024, 1024))\n",
    "\n",
    "    label_name = file.replace('.JPG','.txt')\n",
    "    label_path = os.path.join(labels_folder, label_name)\n",
    "    label_file = pd.read_csv(label_path, header = None,names = ['class', 'x', 'y', 'w', 'h'],sep=\" \")\n",
    "\n",
    "    model_pred_bbox = model_predict(model,processor, img, task_prompt, phrase)\n",
    "\n",
    "    result.append([file,len(label_file),len(model_pred_bbox)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf97cce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>GT</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000.JPG</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001.JPG</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002.JPG</td>\n",
       "      <td>61</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003.JPG</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004.JPG</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0515.JPG</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>0516.JPG</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>0517.JPG</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>0518.JPG</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>0519.JPG</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        image  GT  Prediction\n",
       "0    0000.JPG   8           0\n",
       "1    0001.JPG  15          12\n",
       "2    0002.JPG  61          40\n",
       "3    0003.JPG  12          10\n",
       "4    0004.JPG  14           0\n",
       "..        ...  ..         ...\n",
       "515  0515.JPG  31          30\n",
       "516  0516.JPG  20          17\n",
       "517  0517.JPG  21          16\n",
       "518  0518.JPG   9           9\n",
       "519  0519.JPG   9           0\n",
       "\n",
       "[520 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(result)\n",
    "results_df = result_df.sort_values(by=result_df.columns[0])\n",
    "results_df.reset_index(drop=True, inplace=True)\n",
    "results_df.columns = ['image', 'GT', 'Prediction']\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "327a6fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Mean Absolute Error): 5.3635\n",
      "MSE (Mean Squared Error): 71.6942\n",
      "R2 Score: 0.2789\n"
     ]
    }
   ],
   "source": [
    "y_true = results_df['GT']\n",
    "y_pred = results_df['Prediction']\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"MAE (Mean Absolute Error): {mae:.4f}\")\n",
    "print(f\"MSE (Mean Squared Error): {mse:.4f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70dd6769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving results.\n",
    "results_df.to_csv(\"/home/tanutiwari/Documents/coco/Tomato_count/Data_tomatoes/OD_count.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Oasis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
