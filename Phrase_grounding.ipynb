{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device settings\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "def load_model():\n",
    "    CHECKPOINT = \"microsoft/Florence-2-base-ft\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(CHECKPOINT, trust_remote_code=True).to(device, dtype=torch_dtype)\n",
    "    processor = AutoProcessor.from_pretrained(CHECKPOINT, trust_remote_code=True)\n",
    "    return model, processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, processor = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(model,processor, img, task_prompt, phrase=''):\n",
    "\n",
    "    inputs = processor(text=task_prompt+phrase, images=img, return_tensors=\"pt\").to(device, torch_dtype)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            pixel_values=inputs[\"pixel_values\"],\n",
    "            max_new_tokens=512,\n",
    "            num_beams=3,\n",
    "            do_sample=False\n",
    "        )\n",
    "\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "\n",
    "    parsed_answer = processor.post_process_generation(\n",
    "            generated_text,\n",
    "            task=task_prompt,\n",
    "            image_size=(img.width, img.height))\n",
    "\n",
    "    key = \"<CAPTION_TO_PHRASE_GROUNDING>\"\n",
    "    detections = parsed_answer.get(key, {\"bboxes\": [], \"labels\": []})\n",
    "    bboxes = detections.get(\"bboxes\", [])\n",
    "    labels = detections.get(\"labels\", [])\n",
    "\n",
    "    data = []\n",
    "    area_img  = img.width * img.height\n",
    "\n",
    "    for bbox, label in zip(bboxes, labels):\n",
    "        x_min, y_min, x_max, y_max = map(int, bbox)\n",
    "        bbox_area = (x_max - x_min) * (y_max - y_min)\n",
    "        if bbox_area < 0.7*area_img:\n",
    "            data.append([x_min, y_min, x_max, y_max, label])\n",
    "\n",
    "    return pd.DataFrame(data, columns=[\"x1\", \"y1\", \"x2\", \"y2\", \"object\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Phrase Grounding (PG)', '<CAPTION_TO_PHRASE_GROUNDING>')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# task = \"Object Detection (OD)\"\n",
    "task = \"Phrase Grounding (PG)\"\n",
    "# task = \"Image Captioning (IC)\"\n",
    "\n",
    "phrase = ''\n",
    "if task == \"Object Detection (OD)\":\n",
    "    task_prompt = \"<OD>\"\n",
    "elif task == \"Phrase Grounding (PG)\":\n",
    "    task_prompt = \"<CAPTION_TO_PHRASE_GROUNDING>\"\n",
    "    phrase = 'Red and green tomatoes'\n",
    "\n",
    "else:\n",
    "    task_prompt = \"<CAPTION>\"\n",
    "\n",
    "task , task_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 520/520 [12:51<00:00,  1.48s/it]\n"
     ]
    }
   ],
   "source": [
    "# Loading dataset images and labels\n",
    "img_folder = 'Images'\n",
    "labels_folder = 'labels'\n",
    "\n",
    "result = []\n",
    "\n",
    "for file in tqdm(os.listdir(img_folder)):\n",
    "    if not file.endswith('.JPG'):\n",
    "        continue\n",
    "\n",
    "    image_path = os.path.join(img_folder, file)\n",
    "    img = Image.open(image_path).convert('RGB')  \n",
    "    # img = img.resize((, 224))\n",
    "\n",
    "    label_name = file.replace('.JPG','.txt')\n",
    "    label_path = os.path.join(labels_folder, label_name)\n",
    "    label_file = pd.read_csv(label_path, header = None,names = ['class', 'x', 'y', 'w', 'h'],sep=\" \")\n",
    "\n",
    "    model_pred_bbox = model_predict(model,processor, img, task_prompt, phrase)\n",
    "\n",
    "    result.append([file,len(label_file),len(model_pred_bbox)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>GT</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000.JPG</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001.JPG</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002.JPG</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003.JPG</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004.JPG</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0515.JPG</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>0516.JPG</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>0517.JPG</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>0518.JPG</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>0519.JPG</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        image  GT  Prediction\n",
       "0    0000.JPG   8           0\n",
       "1    0001.JPG  15           1\n",
       "2    0002.JPG  61           0\n",
       "3    0003.JPG  12           1\n",
       "4    0004.JPG  14           0\n",
       "..        ...  ..         ...\n",
       "515  0515.JPG  31           2\n",
       "516  0516.JPG  20           4\n",
       "517  0517.JPG  21           1\n",
       "518  0518.JPG   9           1\n",
       "519  0519.JPG   9           0\n",
       "\n",
       "[520 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(result)\n",
    "results_df = result_df.sort_values(by=result_df.columns[0])\n",
    "results_df.reset_index(drop=True, inplace=True)\n",
    "results_df.columns = ['image', 'GT', 'Prediction']\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Mean Absolute Error): 14.0577\n",
      "MSE (Mean Squared Error): 304.6154\n",
      "R2 Score: -2.0639\n"
     ]
    }
   ],
   "source": [
    "y_true = results_df['GT']\n",
    "y_pred = results_df['Prediction']\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"MAE (Mean Absolute Error): {mae:.4f}\")\n",
    "print(f\"MSE (Mean Squared Error): {mse:.4f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving results.\n",
    "results_df.to_csv(\"/home/tanutiwari/Documents/coco/Tomato_count/Data_tomatoes/results(phrase-Red and green tomatoes).csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Oasis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
